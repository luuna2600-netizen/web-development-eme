{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f2549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ITBIN-2211-0153:  ITBIN-2211-0153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Student ID accepted: ITBIN-2211-0153\n",
      "üî¢ Your unique exam seed is: 863\n",
      "‚ö†Ô∏è Do NOT change or re-run with a different ID. This will affect your dataset and may invalidate your exam.\n"
     ]
    }
   ],
   "source": [
    "# CODE SETUP RUN BEFORE_ALL_CELLS\n",
    "# ---------------------- Setup code (run before all cells) ----------------------\n",
    "# CODE_CELL00: Student Information and Unique Seed Setup\n",
    "# -------------------------------------------------------\n",
    "# üö® This cell MUST be run first. Enter your student ID exactly as on your student card.\n",
    "\n",
    "student_id = input(\"ITBIN-2211-0153: \").strip()\n",
    "\n",
    "if not student_id:\n",
    "    raise ValueError(\"‚ùå Student ID is required to start the exam.\")\n",
    "\n",
    "# Derive a reproducible numeric seed from the student ID\n",
    "seed = sum(ord(ch) for ch in student_id) % 10000\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "print(f\"‚úÖ Student ID accepted: {student_id}\")\n",
    "print(f\"üî¢ Your unique exam seed is: {seed}\")\n",
    "print(\"‚ö†Ô∏è Do NOT change or re-run with a different ID. This will affect your dataset and may invalidate your exam.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcc9f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys import time: 0.000s\n",
      "subprocess import time: 0.000s\n",
      "pkg_resources import time: 0.000s\n",
      "intelligent_systems_exam_group_a * C:\\Users\\student.lab1\\.conda\\envs\\intelligent_systems_exam_group_a\n",
      "Conda env query time: 3.102s\n",
      "Current environment details: intelligent_systems_exam_group_a * C:\\Users\\student.lab1\\.conda\\envs\\intelligent_systems_exam_group_a\n",
      "Python executable: C:\\Users\\student.lab1\\.conda\\envs\\intelligent_systems_exam_group_a\\python.exe\n",
      "Package check time: 0.000s\n",
      "\n",
      "Package verification:\n",
      "['markupsafe', 'pysocks', 'pyyaml', 'send2trash', 'anyio', 'argon2-cffi', 'argon2-cffi-bindings', 'asttokens', 'async-lru', 'attrs', 'babel', 'beautifulsoup4', 'bleach', 'brotlicffi', 'certifi', 'cffi', 'charset-normalizer', 'colorama', 'comm', 'debugpy', 'decorator', 'defusedxml', 'exceptiongroup', 'executing', 'fastjsonschema', 'h11', 'httpcore', 'httpx', 'idna', 'ipykernel', 'ipython', 'jedi', 'jinja2', 'joblib', 'json5', 'jsonschema', 'jsonschema-specifications', 'jupyter-client', 'jupyter-core', 'jupyter-events', 'jupyter-lsp', 'jupyter-server', 'jupyter-server-terminals', 'jupyterlab', 'jupyterlab-pygments', 'jupyterlab-server', 'matplotlib-inline', 'mistune', 'nbclient', 'nbconvert', 'nbformat', 'nest-asyncio', 'notebook', 'notebook-shim', 'numpy', 'overrides', 'packaging', 'pandas', 'pandocfilters', 'parso', 'pip', 'platformdirs', 'prometheus-client', 'prompt-toolkit', 'psutil', 'pure-eval', 'pycparser', 'pygments', 'python-dateutil', 'python-json-logger', 'pytz', 'pywin32', 'pywinpty', 'pyzmq', 'referencing', 'requests', 'rfc3339-validator', 'rfc3986-validator', 'rpds-py', 'scikit-learn', 'scipy', 'setuptools', 'six', 'sniffio', 'soupsieve', 'stack-data', 'terminado', 'threadpoolctl', 'tinycss2', 'tomli', 'tornado', 'traitlets', 'typing-extensions', 'tzdata', 'urllib3', 'wcwidth', 'webencodings', 'websocket-client', 'wheel', 'win-inet-pton', 'autocommand', 'backports.tarfile', 'importlib-metadata', 'inflect', 'jaraco.collections', 'jaraco.context', 'jaraco.functools', 'jaraco.text', 'more-itertools', 'typeguard', 'zipp']\n",
      "‚úì pandas - installed\n",
      "‚úì numpy - installed\n",
      "‚úì scikit-learn - installed\n",
      "‚úó nltk - NOT installed\n",
      "‚úó matplotlib - NOT installed\n",
      "‚úó seaborn - NOT installed\n",
      "‚úó wordcloud - NOT installed\n",
      "‚úó xgboost - NOT installed\n",
      "‚úó imbalanced-learn - NOT installed\n",
      "‚úó spacy - NOT installed\n",
      "‚úó textblob - NOT installed\n",
      "‚úó langdetect - NOT installed\n",
      "‚úó emoji - NOT installed\n",
      "‚úó plotly - NOT installed\n",
      "‚úì scipy - installed\n",
      "Total cell execution time: 3.102s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nIf the above method is slow or not working as expected, you can use the following alternative method:\\nimport importlib.metadata\\n\\nrequired_packages = [\\'pandas\\', \\'numpy\\', \\'scikit-learn\\', \\'nltk\\', \\'matplotlib\\', \\'seaborn\\', \\'wordcloud\\', \\'xgboost\\']\\nprint(\"\\nVerification using importlib.metadata:\")\\n\\nfor package in required_packages:\\n    try:\\n        version = importlib.metadata.version(package)\\n        print(f\"‚úÖ {package} - Installed (Version: {version})\")\\n    except importlib.metadata.PackageNotFoundError:\\n        print(f\"‚ùå {package} - NOT installed\") '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE_CELL01\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "# Profile import times\n",
    "start_total = time.time()\n",
    "start = time.time()\n",
    "import sys\n",
    "print(f\"sys import time: {time.time() - start:.3f}s\")\n",
    "start = time.time()\n",
    "import subprocess\n",
    "print(f\"subprocess import time: {time.time() - start:.3f}s\")\n",
    "start = time.time()\n",
    "import pkg_resources\n",
    "print(f\"pkg_resources import time: {time.time() - start:.3f}s\")\n",
    "\n",
    "# Profile conda environment query\n",
    "start = time.time()\n",
    "try:\n",
    "    env_name = subprocess.check_output(\n",
    "        'conda info --envs | findstr \"*\"',\n",
    "        shell=True\n",
    "    ).decode().strip()\n",
    "    print(env_name)\n",
    "    print(f\"Conda env query time: {time.time() - start:.3f}s\")\n",
    "except Exception as e:\n",
    "    print(f\"Conda env query failed: {e}\")\n",
    "\n",
    "print(\"Current environment details:\", env_name)\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Profile package check\n",
    "start = time.time()\n",
    "required_packages = ['pandas', 'numpy', 'scikit-learn', 'nltk', 'matplotlib', 'seaborn', 'wordcloud', 'xgboost', 'imbalanced-learn', 'spacy', 'textblob', 'langdetect', 'emoji', 'plotly', 'scipy']\n",
    "installed_packages = [pkg.project_name.lower() for pkg in pkg_resources.working_set]\n",
    "print(f\"Package check time: {time.time() - start:.3f}s\")\n",
    "\n",
    "print(\"\\nPackage verification:\")\n",
    "print(installed_packages)\n",
    "\n",
    "for package in required_packages:\n",
    "    if package in installed_packages:\n",
    "        print(f\"‚úì {package} - installed\")\n",
    "    else:\n",
    "        print(f\"‚úó {package} - NOT installed\")\n",
    "\n",
    "print(f\"Total cell execution time: {time.time() - start_total:.3f}s\")\n",
    "\n",
    "\"\"\" \n",
    "If the above method is slow or not working as expected, you can use the following alternative method:\n",
    "import importlib.metadata\n",
    "\n",
    "required_packages = ['pandas', 'numpy', 'scikit-learn', 'nltk', 'matplotlib', 'seaborn', 'wordcloud', 'xgboost']\n",
    "print(\"\\nVerification using importlib.metadata:\")\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        version = importlib.metadata.version(package)\n",
    "        print(f\"‚úÖ {package} - Installed (Version: {version})\")\n",
    "    except importlib.metadata.PackageNotFoundError:\n",
    "        print(f\"‚ùå {package} - NOT installed\") \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4acec7",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL01<br>\n",
    "#### There are main 4 ethical principals. Fairness and justice, accountability and Responsibility, transparency and explainability.below are how these principals are violated.\n",
    "**Faireness and justice**<br>\n",
    "- if ai model gives lower score for women beacause training data had most male employees. this can reject female applications.<br>\n",
    "\n",
    "**Accountability and responsibility**<br>\n",
    "- if candidate reject because of bug in the system but not take responsible for fix it this violate accountability.<br>\n",
    "\n",
    "**Transparancy and explanability**<br>\n",
    "- if the system reject applicant but no explanation why reject applicant. company hr or applicant dont know why decison were made.<br>\n",
    "\n",
    "**emerging framework**<br>\n",
    "- if the company ignore  new ai frameworks or laws\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51b72ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated loan dataset with 1000 applications\n",
      "Overall approval rate: 50.50%\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL02\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_loan_dataset(n_samples=1000):\n",
    "    \"\"\"Generate synthetic loan application dataset with potential bias patterns\"\"\"\n",
    "    \n",
    "    # Demographics with realistic distributions\n",
    "    ages = np.random.normal(35, 12, n_samples).astype(int)\n",
    "    ages = np.clip(ages, 18, 75)\n",
    "    age_groups = ['Young (18-30)', 'Middle (31-50)', 'Senior (51+)']\n",
    "    age_categories = [age_groups[0] if age <= 30 else age_groups[1] if age <= 50 else age_groups[2] for age in ages]\n",
    "    \n",
    "    genders = np.random.choice(['Male', 'Female'], n_samples, p=[0.6, 0.4])\n",
    "    ethnicities = np.random.choice(['White', 'Black', 'Hispanic', 'Asian', 'Other'], \n",
    "                                  n_samples, p=[0.4, 0.3, 0.15, 0.1, 0.05])\n",
    "    \n",
    "    # Financial information\n",
    "    incomes = np.random.lognormal(10.5, 0.8, n_samples)\n",
    "    credit_scores = np.random.normal(650, 100, n_samples).astype(int)\n",
    "    credit_scores = np.clip(credit_scores, 300, 850)\n",
    "    \n",
    "    loan_amounts = np.random.lognormal(10, 0.5, n_samples)\n",
    "    employment_years = np.random.exponential(5, n_samples)\n",
    "    \n",
    "    # Introduce bias: Lower approval rates for certain demographics\n",
    "    base_approval_prob = 0.7\n",
    "    bias_factors = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        prob = base_approval_prob\n",
    "        # Income and credit score effects\n",
    "        prob += (credit_scores[i] - 650) / 1000\n",
    "        prob += min((incomes[i] - 50000) / 100000, 0.2)\n",
    "        \n",
    "        # Introduce systematic bias (this is what students should detect)\n",
    "        if age_categories[i] == 'Young (18-30)':\n",
    "            prob -= 0.15  # Bias against young applicants\n",
    "        if genders[i] == 'Female':\n",
    "            prob -= 0.1   # Bias against female applicants\n",
    "        \n",
    "        bias_factors.append(max(0.05, min(0.95, prob)))\n",
    "    \n",
    "    approvals = np.random.binomial(1, bias_factors, n_samples)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'age': ages,\n",
    "        'age_group': age_categories,\n",
    "        'gender': genders,\n",
    "        'ethnicity': ethnicities,\n",
    "        'annual_income': incomes,\n",
    "        'credit_score': credit_scores,\n",
    "        'loan_amount': loan_amounts,\n",
    "        'employment_years': employment_years,\n",
    "        'approved': approvals\n",
    "    })\n",
    "\n",
    "# Generate the dataset\n",
    "loan_data = generate_loan_dataset()\n",
    "print(f\"Generated loan dataset with {len(loan_data)} applications\")\n",
    "print(f\"Overall approval rate: {loan_data['approved'].mean():.2%}\")\n",
    "\n",
    "loan_data.to_csv(\"loan_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5242eb43",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL_HINT01\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, ttest_ind, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def show_distribution(column):\n",
    "    \"\"\"Show the distribution of a categorical column.\"\"\"\n",
    "    counts = df[column].value_counts(normalize=True) * 100\n",
    "    print(f\"Distribution of {column}:\")\n",
    "    print(counts.round(-))   \n",
    "    counts.plot(kind='bar', title=f\"Distribution of {column}\")\n",
    "    plt.show()\n",
    "\n",
    "def compare_groups(column, target=\"\"): \n",
    "    \"\"\"Compare hiring rates across groups for a categorical variable.\"\"\"\n",
    "    rates = df.groupby(column)[target].mean()\n",
    "    print(f\"Hiring rates by {column}:\")\n",
    "    print(rates.round(2)\n",
    "    rates.plot(kind='bar', title=f\"Hiring rates by {column}\")  \n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram(column): \n",
    "    \"\"\"Plot histogram of a numerical variable.\"\"\"\n",
    "    plt.hist(df[column], bins=20, edgecolor=\"black\")\n",
    "    plt.title(f\"Histogram of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "def chi_square_test(feature, outcome=\"\"): \n",
    "    \"\"\"Chi-square test for independence between two categorical variables.\"\"\"\n",
    "    contingency = pd.crosstab(df[feature], df[outcome])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    print(f\"Chi-square test between {feature} and {outcome}\")\n",
    "    print(f\"Chi2 statistic = {chi2:.2f}, p-value = {p:.4f}\")\n",
    "    return p\n",
    "\n",
    "def t_test_groups(feature, outcome=\"\"): \n",
    "    \"\"\"T-test for comparing means of a numerical feature between hired vs not hired.\"\"\"\n",
    "    group1 = df[df[outcome] == 1][feature]\n",
    "    group0 = df[df[outcome] = 0][feature]  \n",
    "    t_stat, p = ttest_ind(group1, group0, equal_var=False)\n",
    "    print(f\"T-test for {feature} by {outcome}\")\n",
    "    print(f\"T-statistic = {t_stat:.2f}, p-value = {p:.4f}\")\n",
    "    return p\n",
    "\n",
    "def correlation_check(feature, outcome=\"\"):\n",
    "    \"\"\"Pearson correlation between a numerical feature and hiring outcome.\"\"\"\n",
    "    corr, p = pearsonr(df[feature], df[outcome])\n",
    "    print(f\"Correlation between {feature} and {outcome}\")\n",
    "    print(f\"Correlation = {corr:.2f}, p-value = {p:.4f}\")\n",
    "    return corr, p\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4282222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval rates by age_group:\n",
      "age_group\n",
      "Middle (31-50)    0.57\n",
      "Senior (51+)      0.61\n",
      "Young (18-30)     0.37\n",
      "Name: approved, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CODE_CELL03\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def compare_groups(df, column, target=\"approved\"): \n",
    "    \"\"\"Compare rates across groups for a categorical variable.\"\"\"\n",
    "    rates = df.groupby(column)[target].mean()\n",
    "    print(f\"Approval rates by {column}:\")\n",
    "    print(rates.round(2)) \n",
    "    rates.plot(kind='bar', title=f\"Approval rates by {column}\")  \n",
    "    plt.show()\n",
    "\n",
    "# Calling the function\n",
    "compare_groups(loan_data, \"age_group\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f5298f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square test between gender and approved\n",
      "Chi2 statistic = 9.53, p-value = 0.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.0020197371401307817)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE_CELL04\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, ttest_ind, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def chi_square_test(df, feature, outcome=\"approved\"): \n",
    "    \"\"\"Chi-square test for independence between two categorical variables.\"\"\"\n",
    "    contingency = pd.crosstab(df[feature], df[outcome])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    print(f\"Chi-square test between {feature} and {outcome}\")\n",
    "    print(f\"Chi2 statistic = {chi2:.2f}, p-value = {p:.4f}\")\n",
    "    return p\n",
    "\n",
    "# Call the function\n",
    "chi_square_test(df=loan_data, feature='gender', outcome='approved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5b4e2",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL02\n",
    "**chi square test** <br>\n",
    "- This test check there is a meaningful relationship between two categories here- gender and hiring. This is importance for detecting bias between male and females.<br>\n",
    "\n",
    "- In simply this test tell us if the system treate male and female applicant differently in hiring  decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e418bb",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL03\n",
    "\n",
    "#### positive\n",
    "**Faster loan aproval**\n",
    "- AI systems can quickly go loan  applications in minutes. This saves time compared to humans, who would take days or weeks to do the same task.\n",
    "\n",
    "**cheaper** \n",
    "- Companies don‚Äôt need to hire many HR staff or spend money on long recruitment steps. AI reduces the cost by automating most of the work.\n",
    "\n",
    "**can process thousand of loan  applications without tired**\n",
    "- AI can process thousands of loan applications at once without getting tired or bored.\n",
    "\n",
    "#### negative\n",
    "**reduce human judgment**\n",
    "- AI can‚Äôt understand people‚Äôs personality, motivation, or emotions. It may reject good candidates just because their data doesn‚Äôt fit the system‚Äôs pattern.\n",
    "\n",
    "**creativity , empathy not capture in data**\n",
    "- AI focuses on numbers and keywords. its risk.\n",
    "\n",
    "**there is also privacy risk**\n",
    "- collecting and analysing large amount of person data can lead misuse if not properly controlled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756766e",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL04\n",
    "\n",
    "#### below are responsibilities of financial institutions and recommend regulatory complaince measures.\n",
    "\n",
    "- developers must design fair loan aproval algorithms and clear documentation.\n",
    "- management must ensure loan ai tools  meet legal and ethical standards\n",
    "\n",
    "- they must understand how ai works, reviews its recomendations\n",
    "\n",
    "- provide correct information in application\n",
    "\n",
    "#### accountabilities are:\n",
    "- bias check\n",
    "- transparancy report\n",
    "- data protection\n",
    "- regular audit\n",
    "- feedback channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb7d06bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Reviews with Labels:\n",
      "\n",
      "[NEUTRAL] App is okay. Works on Pixel 6 but could use improvements\n",
      "\n",
      "[NEUTRAL] Please add dark mode feature. Otherwise perfect app! 2 stars stars\n",
      "\n",
      "[POSITIVE] ¬°Excelente aplicaci√≥n! Funciona muy bien en mi tel√©fono üì±\n",
      "\n",
      "[NEGATIVE] Crashes when opening notification settings. iPhone 14, Android 11 ü§≥\n",
      "\n",
      "[NEUTRAL] It's fine. Does what it says. Using on iPhone 14\n",
      "\n",
      "\n",
      "Created 100 labeled reviews\n",
      "Positive: 35, Negative: 31, Neutral: 34\n",
      "Reviews DataFrame Head:\n",
      "                                         review_text sentiment_label\n",
      "0  App is okay. Works on Pixel 6 but could use im...         neutral\n",
      "1  Please add dark mode feature. Otherwise perfec...         neutral\n",
      "2  ¬°Excelente aplicaci√≥n! Funciona muy bien en mi...        positive\n",
      "3  Crashes when opening notification settings. iP...        negative\n",
      "4   It's fine. Does what it says. Using on iPhone 14         neutral\n",
      "------------------------------\n",
      "DataFrame Shape: (100, 2)\n",
      "‚úÖ Successfully saved 100 reviews to app_reviews_with_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL05\n",
    "\n",
    "import random\n",
    "\n",
    "# Components to randomly combine with sentiment indicators\n",
    "templates = {\n",
    "    'positive': [\n",
    "        \"Love this app! {stars} Works perfectly on my {device}\",\n",
    "        \"Been using since v{version} - amazing improvements! {device} user here ‚ù§Ô∏è\",\n",
    "        \"¬°Excelente aplicaci√≥n! Funciona muy bien en mi tel√©fono üì±\",\n",
    "        \"„Ç¢„Éó„É™„Åå„Å®„Å¶„ÇÇ‰Ωø„ÅÑ„ÇÑ„Åô„ÅÑ„Åß„Åô„ÄÇ{device}„ÅßÂïèÈ°å„Å™„ÅèÂãï‰Ωú„Åó„Åæ„Åô„ÄÇ\",\n",
    "        \"Fantastic! Best app for productivity. Runs smoothly on {device}\",\n",
    "        \"Highly recommend! {stars} Performance is excellent\",\n",
    "    ],\n",
    "    'negative': [\n",
    "        \"App crashes constantly on {device}. Please fix this bug in v{version} üêõ\",\n",
    "        \"Terrible experience! App won't load on my {device}. {rating} until fixed üò°\",\n",
    "        \"The login feature is broken. Can't sign in with {account_type} account on {device}\",\n",
    "        \"Crashes when opening {feature}. {device}, Android {android_version} ü§≥\",\n",
    "        \"Worst app ever! Constant bugs on {device}. Uninstalling now\",\n",
    "        \"Doesn't work at all. Waste of time on my {device}\",\n",
    "    ],\n",
    "    'neutral': [\n",
    "        \"Great UI design but needs {feature}. Would rate {stars} with that addition\",\n",
    "        \"Please add {feature}. Otherwise perfect app! {rating} stars\",\n",
    "        \"App is okay. Works on {device} but could use improvements\",\n",
    "        \"Decent app. Not great, not terrible. Running v{version}\",\n",
    "        \"It's fine. Does what it says. Using on {device}\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "devices = [\"iPhone 14\", \"Samsung Galaxy S21\", \"iPad Pro\", \"iPhone 13 Pro\", \"Pixel 6\", \"OnePlus 9 Pro\", \"iPhone 12\"]\n",
    "features = [\"dark mode feature\", \"notification settings\", \"multi-language support\", \"offline mode\"]\n",
    "versions = [\"1.0\", \"2.1.3\", \"3.0\", \"4.2.1\"]\n",
    "account_types = [\"Google\", \"Facebook\", \"Apple\"]\n",
    "stars = [\"5 stars ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\", \"4/5 stars\", \"3/5 stars\"]\n",
    "ratings = [\"1 star\", \"2 stars\", \"3 stars\", \"4 stars\", \"5 stars\"]\n",
    "android_versions = [\"12\", \"11\", \"10\"]\n",
    "\n",
    "# Generate labeled app reviews\n",
    "app_reviews_random = []\n",
    "labels = []\n",
    "\n",
    "for _ in range(100):  # generate 100 random reviews\n",
    "    # Choose sentiment category\n",
    "    sentiment = random.choice(['positive', 'negative', 'neutral'])\n",
    "    \n",
    "    # Choose template from that sentiment category\n",
    "    template = random.choice(templates[sentiment])\n",
    "    \n",
    "    # Generate review\n",
    "    review = template.format(\n",
    "        device=random.choice(devices),\n",
    "        feature=random.choice(features),\n",
    "        version=random.choice(versions),\n",
    "        account_type=random.choice(account_types),\n",
    "        stars=random.choice(stars),\n",
    "        rating=random.choice(ratings),\n",
    "        android_version=random.choice(android_versions)\n",
    "    )\n",
    "    \n",
    "    app_reviews_random.append(review)\n",
    "    labels.append(sentiment)\n",
    "\n",
    "# Display samples with labels\n",
    "print(\"Sample Reviews with Labels:\\n\")\n",
    "for r, label in list(zip(app_reviews_random, labels))[:5]:\n",
    "    print(f\"[{label.upper()}] {r}\\n\")\n",
    "\n",
    "print(f\"\\nCreated {len(app_reviews_random)} labeled reviews\")\n",
    "print(f\"Positive: {labels.count('positive')}, Negative: {labels.count('negative')}, Neutral: {labels.count('neutral')}\")\n",
    "\n",
    "# Create a DataFrame from the two lists\n",
    "reviews_df = pd.DataFrame({\n",
    "    'review_text': app_reviews_random,\n",
    "    'sentiment_label': labels\n",
    "})\n",
    "\n",
    "# Display the first few rows to verify the structure\n",
    "print(\"Reviews DataFrame Head:\")\n",
    "print(reviews_df.head())\n",
    "print(\"-\" * 30)\n",
    "print(f\"DataFrame Shape: {reviews_df.shape}\")\n",
    "\n",
    "# 2. Save the DataFrame to a CSV file\n",
    "# index=False prevents pandas from writing the DataFrame index as a column in the CSV\n",
    "csv_filename = \"app_reviews_with_labels.csv\"\n",
    "reviews_df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ Successfully saved {len(reviews_df)} reviews to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836812c3",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL_HINT02\n",
    "\n",
    "```python\n",
    "import re\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "\n",
    "# Load small English NLP model (for NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\"\n",
    "\n",
    "# ---------- Cleaning Functions ----------\n",
    "def basic_clean(text_list):\n",
    "    \"\"\"Lowercase text and remove punctuation.\"\"\"\n",
    "    cleaned = [re.sub(r'[^\\w\\s]', '', t.lower()) for t in text_list]\n",
    "    return cleaned\n",
    "\n",
    "def remove_stopwords(text_list):\n",
    "    \"\"\"Remove common English stopwords.\"\"\"\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    cleaned = []\n",
    "    for t in text_list\n",
    "        tokens = [word for word in t.split() if word not in STOP_WORDS]\n",
    "        cleaned.append(\" \".join(tokens))\n",
    "    return cleaned\n",
    "\n",
    "def normalize_text(text_list):\n",
    "    \"\"\"Handle punctuation, case, and whitespace consistently.\"\"\"\n",
    "    cleaned = [re.sub(r'\\s+', ' ', re.sub(r'[^\\w\\s]', '', t)).strip().lower() for t in text_list]\n",
    "    return cleaned\n",
    "\n",
    "def remove_emojis(text_list):\n",
    "    \"\"\"Remove emojis and other non-text symbols.\"\"\"\n",
    "    cleaned = [emoji.replace_emoji(t, replace='') for t in text_list]\n",
    "    return cleaned\n",
    "\n",
    "# ---------- Entity Extraction ----------\n",
    "def extract_entities_spacy(text_list):\n",
    "    \"\"\"Extract named entities (organizations, products, locations, order numbers).\"\"\"\n",
    "    entities = []\n",
    "    for t in text_list:\n",
    "        doc = nlp(t)\n",
    "        entities.append([(ent.text, ent.label_) for ent in doc.ents])\n",
    "    return entities\n",
    "\n",
    "def extract_numbers(text_list):\n",
    "    \"\"\"Extract numeric values (e.g., order IDs, numbers).\"\"\"\n",
    "    numbers = []\n",
    "    for t in text_list:\n",
    "        nums = re.findall(r'\\d+', t)\n",
    "        numbers.append(nums)\n",
    "    return numbers\n",
    "\n",
    "def remove_urls(text_list):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    cleaned = [re.sub(r'http\\S+|www\\.\\S+', '', t) for t in text_list]\n",
    "    return cleaned\n",
    "\n",
    "def keyword_match(text_list, keywords):\n",
    "    \"\"\"Find keyword matches in text.\"\"\"\n",
    "    matches = []\n",
    "    for t in text_list:\n",
    "        found = [kw for kw in keywords if kw.lower() in t.lower()]\n",
    "        matches.apend(found)\n",
    "    return matches\n",
    "\n",
    "# ---------- Language Detection ----------\n",
    "def detect_language_langdetect(text_list):\n",
    "    \"\"\"Detect the language of each text.\"\"\"\n",
    "    return [detect(t) for t in text_list]\n",
    "\n",
    "def count_words(text_list):\n",
    "    \"\"\"Count words in each feedback.\"\"\"\n",
    "    return [len(t.split()) for t in text_list]\n",
    "\n",
    "def char_length(text_list):\n",
    "    \"\"\"Return character length of each feedback.\"\"\"\n",
    "    return [len(t) for t in text_list]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d1288de",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (3203181438.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[46], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    nlp = spacy.load(\"en_core_web_sm\"\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL06\n",
    "import re\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "\n",
    "# Load small English NLP model (for NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\"\n",
    "\n",
    "# ---------- Cleaning Functions ----------\n",
    "def basic_clean(text_list):\n",
    "    \"\"\"Lowercase text and remove punctuation.\"\"\"\n",
    "    cleaned = [re.sub(r'[^\\w\\s]', '', t.lower()) for t in text_list]\n",
    "    return cleaned\n",
    "\n",
    "def remove_stopwords(text_list):\n",
    "    \"\"\"Remove common English stopwords.\"\"\"\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    cleaned = []\n",
    "    for t in text_list\n",
    "        tokens = [word for word in t.split() if word not in STOP_WORDS]\n",
    "        cleaned.append(\" \".join(tokens))\n",
    "    return cleaned\n",
    "\n",
    "def normalize_text(text_list):\n",
    "    \"\"\"Handle punctuation, case, and whitespace consistently.\"\"\"\n",
    "    cleaned = [re.sub(r'\\s+', ' ', re.sub(r'[^\\w\\s]', '', t)).strip().lower() for t in text_list]\n",
    "    return cleaned\n",
    "\n",
    "def remove_emojis(text_list):\n",
    "    \"\"\"Remove emojis and other non-text symbols.\"\"\"\n",
    "    cleaned = [emoji.replace_emoji(t, replace='') for t in text_list]\n",
    "    return cleaned\n",
    "# Get the list of text data from the DataFrame\n",
    "review_text_list = reviews_df['review_text']\n",
    "\n",
    "# Apply the cleaning functions sequentially\n",
    "normalized_text = normalize_text(review_text_list)\n",
    "print(\"Normalized Text Sample:\")\n",
    "print(normalized_text[:5])\n",
    "print(\"-\" * 30)\n",
    "\n",
    "reviews_without_emojis = remove_emojis(normalized_text)\n",
    "print(\"Text without Emojis Sample:\")\n",
    "print(reviews_without_emojis[:5])\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49337115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_CELL07\n",
    "import re\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "\n",
    "# ---------- Entity Extraction ----------\n",
    "def extract_entities_spacy(text_list):\n",
    "    \"\"\"Extract named entities (organizations, products, locations, order numbers).\"\"\"\n",
    "    entities = []\n",
    "    for t in text_list:\n",
    "        doc = nlp(t)\n",
    "        entities.append([(ent.text, ent.label_) for ent in doc.ents])\n",
    "    return entities\n",
    "\n",
    "def extract_numbers(text_list):\n",
    "    \"\"\"Extract numeric values (e.g., order IDs, numbers).\"\"\"\n",
    "    numbers = []\n",
    "    for t in text_list:\n",
    "        nums = re.findall(r'\\d+', t)\n",
    "        numbers.append(nums)\n",
    "    return numbers\n",
    "\n",
    "def remove_urls(text_list):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    cleaned = [re.sub(r'http\\S+|www\\.\\S+', '', t) for t in text_list]\n",
    "    return cleaned\n",
    "\n",
    "def keyword_match(text_list, keywords):\n",
    "    \"\"\"Find keyword matches in text.\"\"\"\n",
    "    matches = []\n",
    "    for t in text_list:\n",
    "        found = [kw for kw in keywords if kw.lower() in t.lower()]\n",
    "        matches.apend(found)\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e74a573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Language Detection ----------\n",
    "import re\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "\n",
    "def detect_language_langdetect(text_list):\n",
    "    \"\"\"Detect the language of each text.\"\"\"\n",
    "    return [detect(t) for t in text_list]\n",
    "\n",
    "def count_words(text_list):\n",
    "    \"\"\"Count words in each feedback.\"\"\"\n",
    "    return [len(t.split()) for t in text_list]\n",
    "\n",
    "def char_length(text_list):\n",
    "    \"\"\"Return character length of each feedback.\"\"\"\n",
    "    return [len(t) for t in text_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b1079",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL05\n",
    "- remove puntuations , special charactors, stop words\n",
    "- convert everything to lowercase to make it consistence\n",
    "- normalized text to handle extra spaces and diffrence text stlyes\n",
    "- used name entity recognition to organizations, product etc..\n",
    "- use language detection to handle multiplelaguages feedbacks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16abfde5",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL_HINT03\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report _ accuracy_score, confusion_matrix\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # keep only alphabets\n",
    "    return text.strip(\n",
    "\n",
    "# Helper function to build sentiment model\n",
    "def build_sentiment_model()\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_features=5000,\n",
    "        ngram_range=(1 2)\n",
    "    )\n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,  # Increased for convergence\n",
    "        random_state=42,\n",
    "        multi_class='multinomial'  \n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('vectorize', vectorizer),\n",
    "        ('clf', model)\n",
    "    ]\n",
    "    return pipe\n",
    "\n",
    "# Preprocess reviews\n",
    "cleaned_reviews = [clean_text(r) for r in app_reviews_random\n",
    "\n",
    "# Use the actual labels generated with the reviews (not random!)\n",
    "# labels variable should come from the improved CODE_CELL05\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cleaned_reviews, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Label distribution in training: {dict(zip(*zip(*[(l, y_train.count(l)) for l in set(y_train)])))}\\n\")\n",
    "\n",
    "# Train model\n",
    "sentiment_model = build_sentiment_model()\n",
    "sentiment_model.fit(X_train y_train)\n",
    "print(\"Model training completed!\\n\")\n",
    "\n",
    "# Predict on test set (not training set!)\n",
    "predictions = sentiment_model.predict(X_test\n",
    "\n",
    "# Evaluate model performance\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions):.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "\n",
    "# Display sample predictions from test set\n",
    "print(\"=== Sample Predictions ===\")\n",
    "for i in range(min(5 len(X_test))):\n",
    "    original_idx = cleaned_reviews.index(X_test[i])\n",
    "    print(f\"Review: {app_reviews_random[original_idx]}\")\n",
    "    print(f\"‚Üí Actual: {y_test[i]}\")\n",
    "    print(f\"‚Üí Predicted: {predictions[i]}\")\n",
    "    print(f\"‚Üí Match: {'‚úì' if y_test[i] == predictions[i] else '‚úó'}\\n\")\n",
    "\n",
    "# Function to predict sentiment for new reviews\n",
    "def predict_sentiment(review_text, model):\n",
    "    \"\"\"Predict sentiment for a single review or list of reviews\"\"\"\n",
    "    if isinstance(review_text, str):\n",
    "        review_text = [review_text]\n",
    "    \n",
    "    cleaned = [clean_text(r) for r in review_text]\n",
    "    preds\n",
    "\n",
    "# BUG: polarity_score is incomplete\n",
    "def polarity_score(text):\n",
    "    # return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# BUG: classify_sentiment is incomplete\n",
    "def classify_sentiment(score, pos_thresh=0.1, neg_thresh=-0.1):\n",
    "    if score  pos_thresh:\n",
    "        return 'positive'\n",
    "    elif score  neg_thresh:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# BUG: compare_models is incomplete\n",
    "# Assuming logistic_model is already trained from Q(b)(i)\n",
    "def compare_models(texts, model):\n",
    "    model_preds = model.predict(texts)\n",
    "    blob_preds = [classify_sentiment(polarity_score(t)) for t in texts]\n",
    "    comparison = []\n",
    "    for t, m, b in zip(texts, model_preds, blob_preds):\n",
    "        comparison.append((t, m, b))\n",
    "    # return comparison\n",
    "\n",
    "# Apply to reviews\n",
    "cleaned = [r.lower() for r in app_reviews_random]\n",
    "results = compare_models(cleaned, sentiment_model)  # sentiment_model from previous step\n",
    "\n",
    "# Display first 5 comparisons\n",
    "for review, model_p, blob_p in results[:5]:\n",
    "    print(f\"Review: {review}\\nModel: {model_p}\\nTextBlob: {blob_p}\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38d527ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2030731271.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[27], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    from sklearn.metrics import classification_report _ accuracy_score, confusion_matrix\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL09\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report _ accuracy_score, confusion_matrix\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # keep only alphabets\n",
    "    return text.strip(\n",
    "\n",
    "# Helper function to build sentiment model\n",
    "def build_sentiment_model()\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_features=5000,\n",
    "        ngram_range=(1 2)\n",
    "    )\n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,  # Increased for convergence\n",
    "        random_state=42,\n",
    "        multi_class='multinomial'  \n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('vectorize', vectorizer),\n",
    "        ('clf', model)\n",
    "    ]\n",
    "    return pipe\n",
    "\n",
    "# Preprocess reviews\n",
    "cleaned_reviews = [clean_text(r) for r in app_reviews_random\n",
    "\n",
    "# Use the actual labels generated with the reviews (not random!)\n",
    "# labels variable should come from the improved CODE_CELL05\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cleaned_reviews, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Label distribution in training: {dict(zip(*zip(*[(l, y_train.count(l)) for l in set(y_train)])))}\\n\")\n",
    "\n",
    "# Train model\n",
    "sentiment_model = build_sentiment_model()\n",
    "sentiment_model.fit(X_train y_train)\n",
    "print(\"Model training completed!\\n\")\n",
    "\n",
    "# Predict on test set (not training set!)\n",
    "predictions = sentiment_model.predict(X_test\n",
    "\n",
    "# Evaluate model performance\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions):.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "\n",
    "# Display sample predictions from test set\n",
    "print(\"=== Sample Predictions ===\")\n",
    "for i in range(min(5 len(X_test))):\n",
    "    original_idx = cleaned_reviews.index(X_test[i])\n",
    "    print(f\"Review: {app_reviews_random[original_idx]}\")\n",
    "    print(f\"‚Üí Actual: {y_test[i]}\")\n",
    "    print(f\"‚Üí Predicted: {predictions[i]}\")\n",
    "    print(f\"‚Üí Match: {'‚úì' if y_test[i] == predictions[i] else '‚úó'}\\n\")\n",
    "\n",
    "# Function to predict sentiment for new reviews\n",
    "def predict_sentiment(review_text, model):\n",
    "    \"\"\"Predict sentiment for a single review or list of reviews\"\"\"\n",
    "    if isinstance(review_text, str):\n",
    "        review_text = [review_text]\n",
    "    \n",
    "    cleaned = [clean_text(r) for r in review_text]\n",
    "    preds\n",
    "\n",
    "# BUG: polarity_score is incomplete\n",
    "def polarity_score(text):\n",
    "    # return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# BUG: classify_sentiment is incomplete\n",
    "def classify_sentiment(score, pos_thresh=0.1, neg_thresh=-0.1):\n",
    "    if score  pos_thresh:\n",
    "        return 'positive'\n",
    "    elif score  neg_thresh:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# BUG: compare_models is incomplete\n",
    "# Assuming logistic_model is already trained from Q(b)(i)\n",
    "def compare_models(texts, model):\n",
    "    model_preds = model.predict(texts)\n",
    "    blob_preds = [classify_sentiment(polarity_score(t)) for t in texts]\n",
    "    comparison = []\n",
    "    for t, m, b in zip(texts, model_preds, blob_preds):\n",
    "        comparison.append((t, m, b))\n",
    "    # return comparison\n",
    "\n",
    "# Apply to reviews\n",
    "cleaned = [r.lower() for r in app_reviews_random]\n",
    "results = compare_models(cleaned, sentiment_model)  # sentiment_model from previous step\n",
    "\n",
    "# Display first 5 comparisons\n",
    "for review, model_p, blob_p in results[:5]:\n",
    "    print(f\"Review: {review}\\nModel: {model_p}\\nTextBlob: {blob_p}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a26106",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1059341587.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    from sklearn.metrics import classification_report _ accuracy_score, confusion_matrix\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL10\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report _ accuracy_score, confusion_matrix\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # keep only alphabets\n",
    "    return text.strip(\n",
    "\n",
    "# Helper function to build sentiment model\n",
    "def build_sentiment_model()\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_features=5000,\n",
    "        ngram_range=(1 2)\n",
    "    )\n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,  # Increased for convergence\n",
    "        random_state=42,\n",
    "        multi_class='multinomial'  \n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('vectorize', vectorizer),\n",
    "        ('clf', model)\n",
    "    ]\n",
    "    return pipe\n",
    "\n",
    "# Preprocess reviews\n",
    "cleaned_reviews = [clean_text(r) for r in app_reviews_random\n",
    "\n",
    "# Use the actual labels generated with the reviews (not random!)\n",
    "# labels variable should come from the improved CODE_CELL05\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cleaned_reviews, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Label distribution in training: {dict(zip(*zip(*[(l, y_train.count(l)) for l in set(y_train)])))}\\n\")\n",
    "\n",
    "# Train model\n",
    "sentiment_model = build_sentiment_model()\n",
    "sentiment_model.fit(X_train y_train)\n",
    "print(\"Model training completed!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c00e39",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL06\n",
    "\n",
    "**TF-IDF with Logistic Regression often performs better for structured, supervised sentiment analysis tasks, especially with short texts like tweets, because it learns from specific words and their importance. TextBlob's approach is a simpler, pre-built lexicon-based tool that is faster to implement but may be less accurate because it lacks the context and nuance that a machine-learning model can learn**\n",
    "\n",
    "##### TF-IDF + Logistic Regression\n",
    "- How it works\n",
    "- TF-IDF: This method calculates a score for each word based on its frequency in a document (Term Frequency) and its inverse frequency across all documents in the dataset (Inverse Document Frequency).\n",
    "  \n",
    "- Logistic Regression: This is a supervised machine learning algorithm that learns a relationship between the TF-IDF features (word importance scores) and a pre-assigned label\n",
    "\n",
    " **pros**\n",
    " - higher accuracy\n",
    " - handle domain-specific language\n",
    " - high performance\n",
    "\n",
    "**cons**\n",
    "- Requires labeled data\n",
    "- Loses word order\n",
    "\n",
    "##### TextBlob<br>\n",
    "\n",
    "**pros**\n",
    "- Fast and easy to use\n",
    "- No training data needed\n",
    "\n",
    "**Cons**\n",
    "- Limited by its lexicon\n",
    "- Less accurate\n",
    "- Prone to bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06f9c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_CELL11\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_insurance_fraud_dataset(n_samples=2000):\n",
    "    \"\"\"\n",
    "    Generate a synthetic insurance fraud detection dataset.\n",
    "    \n",
    "    Args:\n",
    "        n_samples (int): Number of samples to generate\n",
    "        random_state (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Synthetic insurance fraud dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Policyholder demographics\n",
    "    ages = np.random.randint(18, 80, n_samples)\n",
    "    genders = np.random.choice(['Male', 'Female'], size=n_samples, p=[0.55, 0.45])\n",
    "    policy_tenure = np.random.randint(1, 25, n_samples)  # years with company\n",
    "    \n",
    "    # Policy and claim details\n",
    "    policy_type = np.random.choice(['Comprehensive', 'Third-Party', 'Collision'], size=n_samples, p=[0.6, 0.25, 0.15])\n",
    "    vehicle_age = np.random.randint(0, 20, n_samples)  # years\n",
    "    claim_amount = np.random.normal(5000, 3000, n_samples).clip(100, 30000)\n",
    "    num_previous_claims = np.random.poisson(lam=1.0, size=n_samples)\n",
    "    \n",
    "    # Risk indicators\n",
    "    claim_duration = np.random.randint(1, 90, n_samples)  # days to settle\n",
    "    accident_severity = np.random.choice(['Minor', 'Moderate', 'Severe'], size=n_samples, p=[0.6, 0.3, 0.1])\n",
    "    \n",
    "    # Fraud label (imbalanced: ~15% fraud cases)\n",
    "    fraud_probability = (\n",
    "        (claim_amount > 15000).astype(int) * 0.3 +\n",
    "        (num_previous_claims > 2).astype(int) * 0.2 +\n",
    "        (claim_duration < 5).astype(int) * 0.25 +\n",
    "        (vehicle_age > 15).astype(int) * 0.1\n",
    "    )\n",
    "    fraud_probability = np.clip(fraud_probability, 0, 1)\n",
    "    fraud_label = np.random.binomial(1, p=np.minimum(fraud_probability + 0.05, 0.9))\n",
    "    \n",
    "    # Construct DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'Age': ages,\n",
    "        'Gender': genders,\n",
    "        'PolicyTenure': policy_tenure,\n",
    "        'PolicyType': policy_type,\n",
    "        'VehicleAge': vehicle_age,\n",
    "        'ClaimAmount': claim_amount.round(2),\n",
    "        'NumPreviousClaims': num_previous_claims,\n",
    "        'ClaimDuration': claim_duration,\n",
    "        'AccidentSeverity': accident_severity,\n",
    "        'Fraudulent': fraud_label\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example: Uncomment to generate dataset\n",
    "loan_df = generate_insurance_fraud_dataset(n_samples=2000)\n",
    "# df.head()\n",
    "loan_df.to_csv(\"insurance_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7869c88f",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL_HINT04\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "def plot_distribution(df, column):\n",
    "    \"\"\"\n",
    "    Plot distribution of a numerical or categorical column.\n",
    "    Uses Plotly for interactivity.\n",
    "    \"\"\"\n",
    "    if pd.api.types.is_numeric_dtype(df[column])\n",
    "        fig = px.histogram(df, x=column, nbins=30, title=f\"Distribution of {column}\")\n",
    "    else:\n",
    "        fig = px.bar(df[column].value_counts().reset_index(),\n",
    "                     x=\"index\", y=column, title=f\"Distribution of {column}\")\n",
    "    fig.show \n",
    "    \n",
    "\n",
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"\n",
    "    Plot correlation matrix heatmap for numerical columns.\n",
    "    \"\"\"\n",
    "    corr = df.corr(numeric_only=True)\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=corr.values,\n",
    "        x=list(corr.columns),\n",
    "        y=list(corr.index),\n",
    "        annotation_text=corr.round(2).values,\n",
    "        colorscale=\"Viridis\",\n",
    "    )\n",
    "    fig.update_layout(title=\"Correlation Heatmap\")\n",
    "    fig.show()\n",
    "    return \n",
    "\n",
    "def check_missing_values(df):\n",
    "    \"\"\"\n",
    "    Return missing value counts and percentages per column.\n",
    "    \"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = (missing / len(df)) * 100\n",
    "    # return pd.DataFrame('MissingValues': missing, 'Percentage': missing_percent}) \n",
    "\n",
    "def impute_missing_values(df, strategy=\"mean\", columns=None):\n",
    "    \"\"\"\n",
    "    Impute missing values with statistical strategy (mean, median, mode).\n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        strategy: 'mean', 'median', or 'mode'\n",
    "        columns: list of columns to impute (if None, all numeric columns are used)\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=['float64','int64']).columns\n",
    "    \n",
    "    for col in columns \n",
    "        if strategy == \"mean\":\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        elif strategy == \"median\":\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        elif strategy == \"mode\":\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def detect_outliers_iqr(df, column):\n",
    "    \"\"\"\n",
    "    Detect outliers using IQR method.\n",
    "    Returns indices of outliers.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "    return df[(df[column] < lower) | (df[column] > upper)]index\n",
    "\n",
    "\n",
    "def detect_outliers_zscore(df, column, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect outliers using Z-score method.\n",
    "    Returns indices of outliers.\n",
    "    \"\"\"\n",
    "    z_scores = np.abs(stats.zscore(df[column], nan_policy=\"omit\"))\n",
    "    return df[z_scores > threshold.index] \n",
    "\n",
    "\n",
    "def detect_outliers_isolation_forest(df, columns):\n",
    "    \"\"\"\n",
    "    Detect outliers using Isolation Forest on selected columns.\n",
    "    Returns indices of outliers.\n",
    "    \"\"\"\n",
    "    iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "    preds = iso.fit_predict(df[columns])\n",
    "    return df[preds = -1].index # ERROR\n",
    "\n",
    "\n",
    "def treat_outliers(df, indices, column, method=\"cap\"):\n",
    "    \"\"\"\n",
    "    Treat outliers by either capping or removing them.\n",
    "    Args:\n",
    "        method: 'cap' (replace with percentile bounds) or 'remove' (drop rows)\n",
    "    \"\"\"\n",
    "    if method == \"cap\":\n",
    "        lower, upper = df[column].quantile(0.01), df[column].quantile(0.99)\n",
    "        df.loc[indices, column] = np.clip(df.loc[indices, column], lower, upper)\n",
    "    elif method == \"remove\"\n",
    "        df.drop(indices, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compare_before_after(before_df, after_df, column):\n",
    "    \"\"\"\n",
    "    Compare column statistics before and after cleaning.\n",
    "    Returns a DataFrame with mean, median, std, min, max.\n",
    "    \"\"\"\n",
    "    stats_before = before_df[column].describe()\n",
    "    stats_after = after_df[column].describe()\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        \"Before\": stats_before,\n",
    "        \"After\": stats_after\n",
    "    ) \n",
    "    return comparison\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99e006e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1181212090.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[48], line 19\u001b[1;36m\u001b[0m\n\u001b[1;33m    if pd.api.types.is_numeric_dtype(df[column])\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL12\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "def plot_distribution(df, column):\n",
    "    \"\"\"\n",
    "    Plot distribution of a numerical or categorical column.\n",
    "    Uses Plotly for interactivity.\n",
    "    \"\"\"\n",
    "    if pd.api.types.is_numeric_dtype(df[column])\n",
    "        fig = px.histogram(df, x=column, nbins=30, title=f\"Distribution of {column}\")\n",
    "    else:\n",
    "        fig = px.bar(df[column].value_counts().reset_index(),\n",
    "                     x=\"index\", y=column, title=f\"Distribution of {column}\")\n",
    "    fig.show \n",
    "    \n",
    "\n",
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"\n",
    "    Plot correlation matrix heatmap for numerical columns.\n",
    "    \"\"\"\n",
    "    corr = df.corr(numeric_only=True)\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=corr.values,\n",
    "        x=list(corr.columns),\n",
    "        y=list(corr.index),\n",
    "        annotation_text=corr.round(2).values,\n",
    "        colorscale=\"Viridis\",\n",
    "    )\n",
    "    fig.update_layout(title=\"Correlation Heatmap\")\n",
    "    fig.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a74a74e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3197754971.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[49], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    for col in columns\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL13\n",
    "def check_missing_values(df):\n",
    "    \"\"\"\n",
    "    Return missing value counts and percentages per column.\n",
    "    \"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = (missing / len(df)) * 100\n",
    "    # return pd.DataFrame('MissingValues': missing, 'Percentage': missing_percent}) \n",
    "\n",
    "def impute_missing_values(df, strategy=\"mean\", columns=None):\n",
    "    \"\"\"\n",
    "    Impute missing values with statistical strategy (mean, median, mode).\n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        strategy: 'mean', 'median', or 'mode'\n",
    "        columns: list of columns to impute (if None, all numeric columns are used)\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=['float64','int64']).columns\n",
    "    \n",
    "    for col in columns \n",
    "        if strategy == \"mean\":\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        elif strategy == \"median\":\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        elif strategy == \"mode\":\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41b29e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_CELL14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a88aed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_CELL15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289b567",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL_HINT05\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "RANDOM_STATE = _ # Use the appropriate function np.random.seed(seed) / random.seed(seed)\n",
    "\n",
    "def prepare_data(df, target='Fraudulent', drop_cols=None, scale=True, smote=True):\n",
    "    \"\"\"Split features and label, optionally scale numeric features and apply SMOTE.\"\"\"\n",
    "    if drop_cols is None:\n",
    "        drop_cols = []\n",
    "    X = df.drop(columns=[target] + drop_cols)\n",
    "    # One-hot encode categoricals\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    y = df[target].values\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                        stratify=y, random_state=RANDOM_STATE)\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    if smote:\n",
    "        sm = SMOTE(random_state=RANDOM_STATE)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def build_xgboost(X_train, y_train):\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def build_svm(X_train, y_train, class_weight='balanced'):\n",
    "    model = SVC(probability=True, class_weight=class_weight, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Return dict of precision, recall, f1, auc_roc, auc_pr.\"\"\"\n",
    "    # predictions and probabilities\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        # Keras model: predict returns probabilities\n",
    "        y_prob = model.predict(X_test).ravel()\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
    "    aucroc = roc_auc_score(y_test, y_prob)\n",
    "    aucpr = average_precision_score(y_test, y_prob)\n",
    "    return {'precision': p, 'recall': r, 'f1': f, 'aucroc': aucroc, 'aucpr': aucpr, 'y_prob': y_prob, 'y_pred': y_pred}\n",
    "\n",
    "def stratified_cv_scores(model_builder, X, y, n_splits=5):\n",
    "    \"\"\"Return cross-validated AUC-PR scores using StratifiedKFold.\n",
    "       model_builder is a callable that returns a fitted model when given X_train,y_train.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        Xtr, Xv = X[train_idx], X[val_idx]\n",
    "        ytr, yv = y[train_idx], y[val_idx]\n",
    "        m = model_builder(Xtr, ytr)\n",
    "        if hasattr(m, \"predict_proba\"):\n",
    "            prob = m.predict_proba(Xv)[:,1]\n",
    "        else:\n",
    "            prob = m.predict(Xv).ravel()\n",
    "        scores.append(average_precision_score(yv, prob))\n",
    "    return scores\n",
    "\n",
    "def plot_learning_curves(estimator, X, y, title='Learning Curve'):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(estimator, X, y, cv=5,\n",
    "                                                           scoring='average_precision',\n",
    "                                                           train_sizes=np.linspace(0.1,1.0,5),\n",
    "                                                           n_jobs=1)\n",
    "    plt.plot(train_sizes, np.mean(train_scores, axis=1), label='train')\n",
    "    plt.plot(train_sizes, np.mean(val_scores, axis=1), label='validation')\n",
    "    plt.xlabel('Train size')\n",
    "    plt.ylabel('Average Precision')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45689a22",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (361812290.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[47], line 15\u001b[1;36m\u001b[0m\n\u001b[1;33m    def prepare_data(df, target='Fraudulent', drop_cols=None, scale=True, smote=True):\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# CODE_CELL16\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "RANDOM_STATE = _ # Use the appropriate function np.random.seed(seed) / random.seed(seed)\n",
    "\n",
    "def prepare_data(df, target='Fraudulent', drop_cols=None, scale=True, smote=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38afbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_CELL17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f835913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_CELL18\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34b51d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_CELL19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c270c",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001011d5",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL08 <br>\n",
    " **A Turing mean A test of a machine's ability to exhibit intelligent behaviour equivalent to that of a human**\n",
    "\n",
    " **Limitations of Turing Test**\n",
    " \n",
    " -Limited Measure of Intelligence: The Turing Test focuses on language capabilities, offering a limited perspective on overall machine intelligence in areas like problem-solving, learning, and reasoning.\n",
    "\n",
    " - Narrow scope: The test only looks at conversation. It ignores other signs of intelligence like creativity, emotional understanding, or solving real-world problems.\n",
    "\n",
    " - Encourages faking it: The test rewards tricking a human judge, not showing true intelligence. This means AIs might be programmed to make mistakes on purpose to seem more human.\n",
    "\n",
    " - Limited context: Modern AIs can do many intelligent things, like create images, code, and more, which the simple, text-based Turing Test cannot measure. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0760f",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL09 <br>\n",
    "**Example 1: Document processing and data extraction with Named Entity Recognition**\n",
    "- Data ingestion and knowledge extraction<br>\n",
    "\n",
    "**Example 2: Sentiment analysis for risk identification**\n",
    "  \n",
    "- Risk assessment and reasoning\n",
    "- Recommendation and human review\n",
    "\n",
    "**Example 3: Constructing a knowledge graph for a holistic view**\n",
    "\n",
    "**Example 4: Generating explanations with Chain-of-Thought (CoT) reasoning**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b5dd4",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL10\n",
    "**Transparency and explainability**\n",
    "\n",
    "**fairness and justice**\n",
    "- given oppotunities for all male and female persons\n",
    "\n",
    "**accountablity and responsibility**\n",
    "- ifn system has bug they are responsible for fix issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18812b24",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL11\n",
    "\n",
    "- Fairness: Retrain models on balanced data, not historical data\n",
    "- Transparency: Implement Explainable AI (XAI) tools.\n",
    "- Accountability: Create an independent oversight committee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60530fa",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL12\n",
    "- Ignoring AI fairness and transparency can lead to heavy regulatory fines and lawsuits, significant brand damage and loss of customer trust, and worsening societal inequality through biased decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fa376",
   "metadata": {},
   "source": [
    "MARKDOWN_CELL13\n",
    "\n",
    "- It balances innovation with responsibility.\n",
    "- It protects the brand by proactively managing ethical and regulatory risks from biased historical data.\n",
    "- It allows for safe, controlled testing, validating fairness and performance in the real world before full deployment. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
